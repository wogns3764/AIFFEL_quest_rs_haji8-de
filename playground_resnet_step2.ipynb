{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/haji8-de/AIFFEL_quest_rs/blob/main/playground_resnet_step2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHmJbXBks8pG"
      },
      "source": [
        "# 기본 초기화 소스"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PU4ol_fiKTOD"
      },
      "outputs": [],
      "source": [
        "!pip install torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2hyrckZzxIQD"
      },
      "outputs": [],
      "source": [
        "# Pytorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchinfo import summary\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AeE3xIbtJMMM"
      },
      "outputs": [],
      "source": [
        "def imshow(img):\n",
        "    img = img / 2 + 0.5\n",
        "    npimg = img.numpy()\n",
        "    return np.transpose(npimg, (1, 2, 0))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQskIfX-yMVu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MyOFxhzqKTOV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import models\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "\n",
        "hyperparams = {\n",
        "    \"batch_size\": 4,\n",
        "    \"learning_rate\": 0.0001,\n",
        "    \"epochs\": 5,\n",
        "    \"transform\": transforms.Compose(\n",
        "        [\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(\n",
        "                mean=[0.48235, 0.45882, 0.40784],\n",
        "                std=[0.229, 0.224, 0.225],\n",
        "            ),\n",
        "        ]\n",
        "    ),\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h16SxMH4tGaz"
      },
      "source": [
        "## 데이터 로드 소스 from torchVision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KrWgUf69OM9E"
      },
      "outputs": [],
      "source": [
        "trainset = torchvision.datasets.Imagenette(root='./data', split='train', download=True, transform=hyperparams['transform'])\n",
        "testset = torchvision.datasets.Imagenette(root='./data', split='val', download=True, transform=hyperparams['transform'])\n",
        "\n",
        "trainloader_2 = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)\n",
        "testloader_2 = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False)\n",
        "\n",
        "# trainloader_2 = torch.utils.data.DataLoader(ds_split['train'], batch_size=32, shuffle=True)\n",
        "# testloader_2 = torch.utils.data.DataLoader(ds_split['test'], batch_size=32, shuffle=False)\n",
        "# validationloader_2 = torch.utils.data.DataLoader(ds_split['validation'], batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MVCTX7gOsjt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qeb3sP1ktMw8"
      },
      "source": [
        "## 이진 분류된 이미지의 결과를 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67d5ed55"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def show_multiple_images(data_loader, n_images=9):\n",
        "    # 1. 데이터 로더에서 배치 가져오기\n",
        "    # iter(dataset)이 아니라 iter(data_loader)를 사용해야 배치가 나옵니다.\n",
        "    dataiter = iter(data_loader)\n",
        "    images, labels = next(dataiter)\n",
        "\n",
        "    fig, axes = plt.subplots(3, 3, figsize=(12, 12))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    # 요청하신 labels_list (ImageNet 스타일 클래스명)\n",
        "    labels_list = [\n",
        "        ('tench', 'Tinca tinca'),\n",
        "        ('English springer', 'English springer spaniel'),\n",
        "        ('cassette player',),\n",
        "        ('chain saw', 'chainsaw'),\n",
        "        ('church', 'church building'),\n",
        "        ('French horn', 'horn'),\n",
        "        ('garbage truck', 'dustcart'),\n",
        "        ('gas pump', 'gasoline pump', 'petrol pump', 'island dispenser'),\n",
        "        ('golf ball',),\n",
        "        ('parachute', 'chute')\n",
        "    ]\n",
        "\n",
        "    for i in range(n_images):\n",
        "        ax = axes[i]\n",
        "\n",
        "        # 2. 이미지 역정규화 (Un-normalization)\n",
        "        # Tensor(C,H,W) -> Numpy(H,W,C)\n",
        "        img = images[i].cpu().numpy().transpose((1, 2, 0))\n",
        "\n",
        "        # 일반적인 ImageNet/ResNet 정규화 값 (Mean/Std) 복원\n",
        "        mean = np.array([0.485, 0.456, 0.406])\n",
        "        std = np.array([0.229, 0.224, 0.225])\n",
        "        img = std * img + mean\n",
        "        img = np.clip(img, 0, 1) # 0~1 사이로 자름\n",
        "\n",
        "        ax.imshow(img)\n",
        "\n",
        "        # 3. 라벨 인덱스 추출 (IndexError 방지 로직 포함)\n",
        "        # labels가 [binary, breed] 리스트인지, 그냥 텐서인지 확인\n",
        "        if isinstance(labels, list):\n",
        "            label_idx = labels[0][i].item()\n",
        "        else:\n",
        "            label_idx = labels[i].item()\n",
        "\n",
        "        # 4. 텍스트 매핑 (튜플 처리)\n",
        "        if 0 <= label_idx < len(labels_list):\n",
        "            # 튜플의 첫 번째 요소만 가져옴 (예: 'tench')\n",
        "            label_text = labels_list[label_idx][0]\n",
        "        else:\n",
        "            # 리스트 범위를 벗어나는 인덱스가 나오면 숫자만 출력\n",
        "            label_text = f\"Unknown ({label_idx})\"\n",
        "\n",
        "        ax.set_title(f\"{label_text}\", fontsize=10)\n",
        "        ax.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b9ff5395"
      },
      "outputs": [],
      "source": [
        "# trainloader_2 에 대한 이진 레이블 시각화\n",
        "\n",
        "# --- 실행 ---\n",
        "# 주의: 함수 인자에는 Dataset이 아니라 DataLoader를 넣어야 합니다.\n",
        "print(\"Trainloader_2 (Labels):\")\n",
        "show_multiple_images(trainloader_2)\n",
        "\n",
        "\n",
        "# testloader_2 에 대한 이진 레이블 시각화\n",
        "print(\"\\nTestloader_2 (Labels):\")\n",
        "show_multiple_images(testloader_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPLRP_iZxTO9"
      },
      "source": [
        "# ResNet 구현체"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BasicBlock"
      ],
      "metadata": {
        "id": "91aCUMrMFNAt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dynO2yoHKGZd"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            inplanes, planes,\n",
        "            kernel_size=3, stride=stride, padding=1, bias=False\n",
        "        )\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            planes, planes,\n",
        "            kernel_size=3, stride=1, padding=1, bias=False\n",
        "        )\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or inplanes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(\n",
        "                    inplanes, self.expansion*planes,\n",
        "                    kernel_size=1, stride=stride, bias=False\n",
        "                ),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out += self.shortcut(x)\n",
        "        out = self.relu(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V2Ikz1M1FRmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## resnet 구현체"
      ],
      "metadata": {
        "id": "PoSxKL9iFVJN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ocWtDQzAKI7Y"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, layers, num_classes=1000):\n",
        "        super().__init__()\n",
        "\n",
        "        self.inplanes = 64\n",
        "        self.stem = nn.Sequential(\n",
        "            nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3, bias=False),\n",
        "            nn.BatchNorm2d(self.inplanes),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        )\n",
        "        self.stage1 = self._make_layer(block, 64, layers[0], stride=1)\n",
        "        self.stage2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.stage3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.stage4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for _ in range(num_blocks - 1):\n",
        "            layers.append(block(self.inplanes, planes, 1))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.stem(x)\n",
        "        out = self.stage1(out)\n",
        "        out = self.stage2(out)\n",
        "        out = self.stage3(out)\n",
        "        out = self.stage4(out)\n",
        "        out = self.avgpool(out)\n",
        "        out = torch.flatten(out, 1)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 다양한 resnet 생성"
      ],
      "metadata": {
        "id": "ggX8eqqGFhJW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MwI1e8N2KTOc"
      },
      "outputs": [],
      "source": [
        "from torchvision import models\n",
        "from torchinfo import summary\n",
        "\n",
        "resnet34 = ResNet(BasicBlock, [3, 4, 6, 3], 10)\n",
        "torch_model = models.resnet34(weights=\"ResNet34_Weights.IMAGENET1K_V1\")\n",
        "\n",
        "resnet34_info = summary(resnet34, (1, 3, 224, 224), verbose=0)\n",
        "torch_model_info = summary(torch_model, (1, 3, 224, 224), verbose=0)\n",
        "\n",
        "print(resnet34_info.total_params)\n",
        "print(torch_model_info.total_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## display_predictions\n",
        "\n",
        "\n",
        "예측된 라벨의 정확도 확인을 위해\n",
        "예측라벨과 정답 라벨을 이미지와 함께 노출\n",
        "\n",
        "* class_names = ['cat', 'dog']"
      ],
      "metadata": {
        "id": "TO2b18mnGRFY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7g9uNPp9qkJ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# 전역 변수로 정의\n",
        "labels_list = [\n",
        "        ('tench', 'Tinca tinca'),\n",
        "        ('English springer', 'English springer spaniel'),\n",
        "        ('cassette player',),\n",
        "        ('chain saw', 'chainsaw'),\n",
        "        ('church', 'church building'),\n",
        "        ('French horn', 'horn'),\n",
        "        ('garbage truck', 'dustcart'),\n",
        "        ('gas pump', 'gasoline pump', 'petrol pump', 'island dispenser'),\n",
        "        ('golf ball',),\n",
        "        ('parachute', 'chute')\n",
        "    ]\n",
        "\n",
        "def show_multiple_images(loader, n_images=9):\n",
        "    \"\"\"\n",
        "    데이터셋의 정답 라벨(Ground Truth)만 확인하는 함수\n",
        "    \"\"\"\n",
        "    # 1. 데이터 로더에서 배치 가져오기\n",
        "    dataiter = iter(loader)\n",
        "    images, labels = next(dataiter)\n",
        "\n",
        "    fig, axes = plt.subplots(3, 3, figsize=(10, 10))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    for i in range(n_images):\n",
        "        if i >= len(images): break # 배치 크기가 n_images보다 작을 경우 방지\n",
        "\n",
        "        ax = axes[i]\n",
        "\n",
        "        # 2. 이미지 역정규화 (Tensor -> Numpy & Un-normalize)\n",
        "        img = images[i].cpu().numpy().transpose((1, 2, 0))\n",
        "        mean = np.array([0.485, 0.456, 0.406])\n",
        "        std = np.array([0.229, 0.224, 0.225])\n",
        "        img = std * img + mean\n",
        "        img = np.clip(img, 0, 1)\n",
        "\n",
        "        ax.imshow(img)\n",
        "\n",
        "        # 3. 라벨 추출 (IndexError 방지: 리스트인지 텐서인지 확인)\n",
        "        if isinstance(labels, list):\n",
        "            binary_label_idx = labels[0][i].item() # [binary, breed] 형태일 때\n",
        "        else:\n",
        "            binary_label_idx = labels[i].item()    # 그냥 텐서일 때\n",
        "\n",
        "        # 4. 텍스트 매핑\n",
        "        if 0 <= binary_label_idx < len(binary_labels_map):\n",
        "            label_text = binary_labels_map[binary_label_idx]\n",
        "        else:\n",
        "            label_text = f\"Unknown ({binary_label_idx})\"\n",
        "\n",
        "        ax.set_title(f\"True: {label_text}\")\n",
        "        ax.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def display_predictions(loader, model, class_names, device, n_images=9):\n",
        "    \"\"\"\n",
        "    모델의 예측값(Prediction)과 정답(True)을 비교하는 함수\n",
        "    \"\"\"\n",
        "    # 1. 데이터 가져오기\n",
        "    dataiter = iter(loader)\n",
        "    images, labels = next(dataiter)\n",
        "\n",
        "    fig, axes = plt.subplots(3, 3, figsize=(10, 10))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    # 모델 평가 모드 전환 (중요)\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i in range(n_images):\n",
        "            if i >= len(images): break\n",
        "\n",
        "            ax = axes[i]\n",
        "\n",
        "            # 2. 이미지 역정규화 및 출력\n",
        "            img = images[i].cpu().numpy().transpose((1, 2, 0))\n",
        "            mean = np.array([0.485, 0.456, 0.406])\n",
        "            std = np.array([0.229, 0.224, 0.225])\n",
        "            img = std * img + mean\n",
        "            img = np.clip(img, 0, 1)\n",
        "\n",
        "            ax.imshow(img)\n",
        "\n",
        "            # 3. 모델 예측\n",
        "            # 배치 차원 추가 [3, 224, 224] -> [1, 3, 224, 224] 후 디바이스로 이동\n",
        "            input_tensor = images[i].unsqueeze(0).to(device)\n",
        "            outputs = model(input_tensor)\n",
        "\n",
        "            # 예측 클래스 인덱스 가져오기\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            predicted_idx = predicted.item()\n",
        "\n",
        "            # 예측된 클래스 이름 (class_names 리스트 사용)\n",
        "            if 0 <= predicted_idx < len(class_names):\n",
        "                predicted_class_name = class_names[predicted_idx]\n",
        "            else:\n",
        "                predicted_class_name = f\"Idx {predicted_idx}\"\n",
        "\n",
        "            # 4. 실제 정답 라벨 추출 (IndexError 방지 로직)\n",
        "            if isinstance(labels, list):\n",
        "                true_idx = labels[0][i].item()\n",
        "            else:\n",
        "                true_idx = labels[i].item()\n",
        "\n",
        "            # 정답 클래스 이름 (binary_labels_map 사용)\n",
        "            if 0 <= true_idx < len(labels_list):\n",
        "                true_label_text = labels_list[true_idx]\n",
        "            else:\n",
        "                true_label_text = f\"Unknown ({true_idx})\"\n",
        "\n",
        "            # 5. 제목 설정 (True vs Pred)\n",
        "            # 정답과 예측이 다르면 빨간색으로 표시하는 로직 추가 (선택사항)\n",
        "            title_color = 'black' if true_idx == predicted_idx else 'red'\n",
        "\n",
        "            ax.set_title(f\"True: {true_label_text}\\nPred: {predicted_class_name}\", color=title_color)\n",
        "            ax.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    # 모델을 다시 train 모드로 돌려놓으려면 주석 해제\n",
        "    # model.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oA8q22cJkSTe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9KVnLfg0kSTg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OmcMzgB02zb"
      },
      "source": [
        "# ResNet-34, ResNet-50 각각 plain모델과 residual모델"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PlainBlock 선언"
      ],
      "metadata": {
        "id": "oPopdN_pGpZA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cy-bjOzo01m3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class PlainBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    ResNet의 BasicBlock과 구조는 같지만,\n",
        "    Skip Connection(+ identity)이 없는 블록\n",
        "    \"\"\"\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(PlainBlock, self).__init__()\n",
        "\n",
        "        # 첫 번째 Conv (Stride가 1이 아닐 수도 있음)\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3,\n",
        "                               stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        # 두 번째 Conv\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 1. Convolution 통과\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        # [차이점] 여기서 ResNet은 'out += x'를 하지만, Plain 모델은 하지 않습니다.\n",
        "\n",
        "        out = self.relu(out)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bulid Plainnet 선언"
      ],
      "metadata": {
        "id": "k-qSo8J-GvoA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wyvfHH8x0HkM"
      },
      "outputs": [],
      "source": [
        "def build_plainnet(is_50=False, input_shape=(32, 32, 3), num_classes=10):\n",
        "    \"\"\"\n",
        "    ResNet-34와 동일한 층 수를 가지지만,\n",
        "    Skip Connection이 없는 PlainNet-34 모델을 생성합니다.\n",
        "    \"\"\"\n",
        "\n",
        "    # ResNet-34와 동일한 레이어 구성\n",
        "    layers = [3, 4, 6, 3]\n",
        "\n",
        "    # 블록 타입으로 BasicBlock 대신 PlainBlock을 사용\n",
        "    # is_50(Bottleneck) 옵션은 PlainNet 실험에서 보통 34층 이하를 비교하므로 무시하거나 False로 둠\n",
        "    model = ResNet(PlainBlock, layers, num_classes=num_classes)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## plainnet_34_2 수행"
      ],
      "metadata": {
        "id": "jeb-EOORG3Hp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2JFSlQ0KTOn",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "plainnet_34_2 = build_plainnet(is_50=False, input_shape=(32, 32,3), num_classes=10)\n",
        "# print(summary(plainnet_34_2))\n",
        "\n",
        "# print(plainnet_34_2.total_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 학습부"
      ],
      "metadata": {
        "id": "5TgRfmBrHHSg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2Xco9d8kSTo"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 256\n",
        "EPOCH = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rMPXRVzVkSTr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MeDUCnml2EGH"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "def model_run_epoch_classnet(origin_model):\n",
        "    # 1. Setup\n",
        "    current_time = time.time()\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    # Move model to device FIRST\n",
        "    model = origin_model.to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "    # CRITICAL FIX 1: Optimizer must be defined AFTER moving model to device.\n",
        "    # We must optimize 'model.parameters()', NOT 'origin_model.parameters()'.\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)\n",
        "\n",
        "    origin_model_train_losses = []\n",
        "    origin_model_val_accuracy = []\n",
        "\n",
        "    print(f\"Training on device: {device}\")\n",
        "\n",
        "    # Ensure EPOCH is defined (or pass it as an argument). Assuming global variable for now.\n",
        "    for epoch in range(EPOCH):\n",
        "        # CRITICAL FIX 2: Use local 'model' variable, not global 'resnet34'\n",
        "        model.train()\n",
        "\n",
        "        running_loss = 0.0\n",
        "        epoch_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        # --- TRAINING LOOP ---\n",
        "        for i, (inputs, labels) in enumerate(trainloader_2, 0):\n",
        "            inputs = inputs.to(device)\n",
        "\n",
        "            # --- [FIX FOR VALUE ERROR: TARGET UNPACKING] ---\n",
        "            # Handles both list (multi-label) and tensor (single-label) cases\n",
        "            if isinstance(labels, list):\n",
        "                targets = labels[0].to(device).long()\n",
        "            else:\n",
        "                targets = labels.to(device).long()\n",
        "            # -----------------------------------------------\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            # Safety Check: Prevent crash if shapes mismatch\n",
        "            if targets.shape[0] != outputs.shape[0]:\n",
        "                 print(f\"Error: Shape Mismatch! Output: {outputs.shape}, Target: {targets.shape}\")\n",
        "                 continue # Skip this batch\n",
        "\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Stats\n",
        "            loss_val = loss.item()\n",
        "            running_loss += loss_val\n",
        "            epoch_loss += loss_val\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += targets.size(0)\n",
        "            correct += (predicted == targets).sum().item()\n",
        "\n",
        "            if i % 100 == 99:\n",
        "                print(f\"[{epoch + 1}, {i + 1:5d}] Step Loss: {running_loss / 100:.3f}\")\n",
        "                running_loss = 0.0\n",
        "\n",
        "        # End of Training Epoch Stats\n",
        "        avg_train_loss = epoch_loss / len(trainloader_2)\n",
        "        train_acc = 100 * correct / total\n",
        "        origin_model_train_losses.append(avg_train_loss)\n",
        "\n",
        "        print(f\"Epoch {epoch + 1} Finished. Avg Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
        "\n",
        "        # --- VALIDATION LOOP ---\n",
        "        model.eval()\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in testloader_2:\n",
        "                inputs = inputs.to(device)\n",
        "\n",
        "                # --- [FIX APPLIED TO VALIDATION TOO] ---\n",
        "                if isinstance(labels, list):\n",
        "                    targets = labels[0].to(device).long()\n",
        "                else:\n",
        "                    targets = labels.to(device).long()\n",
        "                # ---------------------------------------\n",
        "\n",
        "                outputs = model(inputs)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "                val_total += targets.size(0)\n",
        "                val_correct += (predicted == targets).sum().item()\n",
        "\n",
        "        if val_total > 0:\n",
        "            val_acc = 100 * val_correct / val_total\n",
        "        else:\n",
        "            val_acc = 0.0\n",
        "\n",
        "        origin_model_val_accuracy.append(val_acc)\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}: Validation Accuracy: {val_acc:.2f}%\")\n",
        "        print(\"-\" * 20)\n",
        "\n",
        "    print(\"Finished Training\")\n",
        "    print(f\"Time elapsed: {time.time() - current_time:.2f} seconds\")\n",
        "\n",
        "    return origin_model_train_losses, origin_model_val_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gdb30TxX2HsG",
        "outputId": "d66c6091-47d9-4eca-da2a-de21c6cd4472"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on device: cuda\n",
            "[1,   100] Step Loss: 2.005\n",
            "[1,   200] Step Loss: 1.564\n",
            "Epoch 1 Finished. Avg Loss: 1.6413, Train Acc: 43.25%\n",
            "Epoch 1: Validation Accuracy: 40.61%\n",
            "--------------------\n",
            "[2,   100] Step Loss: 1.220\n",
            "[2,   200] Step Loss: 1.111\n",
            "Epoch 2 Finished. Avg Loss: 1.1408, Train Acc: 62.63%\n",
            "Epoch 2: Validation Accuracy: 56.03%\n",
            "--------------------\n",
            "[3,   100] Step Loss: 0.916\n",
            "[3,   200] Step Loss: 0.875\n",
            "Epoch 3 Finished. Avg Loss: 0.8999, Train Acc: 70.48%\n",
            "Epoch 3: Validation Accuracy: 69.89%\n",
            "--------------------\n",
            "[4,   100] Step Loss: 0.791\n",
            "[4,   200] Step Loss: 0.718\n",
            "Epoch 4 Finished. Avg Loss: 0.7459, Train Acc: 76.06%\n",
            "Epoch 4: Validation Accuracy: 66.14%\n",
            "--------------------\n",
            "[5,   100] Step Loss: 0.623\n",
            "[5,   200] Step Loss: 0.614\n",
            "Epoch 5 Finished. Avg Loss: 0.6313, Train Acc: 79.70%\n",
            "Epoch 5: Validation Accuracy: 65.83%\n",
            "--------------------\n",
            "[6,   100] Step Loss: 0.480\n",
            "[6,   200] Step Loss: 0.496\n",
            "Epoch 6 Finished. Avg Loss: 0.5052, Train Acc: 83.28%\n",
            "Epoch 6: Validation Accuracy: 69.89%\n",
            "--------------------\n",
            "[7,   100] Step Loss: 0.330\n",
            "[7,   200] Step Loss: 0.380\n",
            "Epoch 7 Finished. Avg Loss: 0.3819, Train Acc: 87.51%\n",
            "Epoch 7: Validation Accuracy: 68.31%\n",
            "--------------------\n",
            "[8,   100] Step Loss: 0.242\n",
            "[8,   200] Step Loss: 0.286\n",
            "Epoch 8 Finished. Avg Loss: 0.2992, Train Acc: 90.19%\n",
            "Epoch 8: Validation Accuracy: 69.96%\n",
            "--------------------\n",
            "[9,   100] Step Loss: 0.196\n",
            "[9,   200] Step Loss: 0.232\n",
            "Epoch 9 Finished. Avg Loss: 0.2257, Train Acc: 92.47%\n",
            "Epoch 9: Validation Accuracy: 72.46%\n",
            "--------------------\n",
            "[10,   100] Step Loss: 0.131\n",
            "[10,   200] Step Loss: 0.133\n"
          ]
        }
      ],
      "source": [
        "l34,a34 = model_run_epoch_classnet(resnet34)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8OTFjiU42Jza"
      },
      "outputs": [],
      "source": [
        "lp34,ap34 = model_run_epoch_classnet(plainnet_34_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lo48nQmOFDwE"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def figure_2chart(title, l1,a1,l2,a2):\n",
        "\n",
        "    # --- 데이터 준비 (예시 변수명입니다. 실제 저장한 변수명으로 교체하세요) ---\n",
        "    # 예: epochs = range(1, 11)\n",
        "    epochs = range(1, len(a1) + 1)\n",
        "\n",
        "    # 1. 그래프 크기 설정\n",
        "    plt.figure(figsize=(15, 6))\n",
        "\n",
        "    # -------------------------------------------------------\n",
        "    # [왼쪽 그래프] Validation Accuracy 비교\n",
        "    # -------------------------------------------------------\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, a1, 'b-o', label='Res'+title+' (Shortcut O)')\n",
        "    plt.plot(epochs, a2, 'r--s', label='Plain'+title+' (Shortcut X)')\n",
        "\n",
        "    plt.title('Validation Accuracy Comparison', fontsize=15)\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy (%)')\n",
        "    plt.grid(True, linestyle='--', alpha=0.6)\n",
        "    plt.legend(fontsize=12)\n",
        "\n",
        "    # -------------------------------------------------------\n",
        "    # [오른쪽 그래프] Validation Loss 비교\n",
        "    # (Loss 리스트가 있다면 이 부분을 주석 해제하고 사용하세요)\n",
        "    # -------------------------------------------------------\n",
        "    plt.subplot(1, 2, 2)\n",
        "\n",
        "    plt.plot(epochs, l1, 'b-o', label='Res'+title+' Loss')\n",
        "    plt.plot(epochs, l2, 'r--s', label='Plain'+title+' Loss')\n",
        "    plt.title('Validation Loss Comparison', fontsize=15)\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.grid(True, linestyle='--', alpha=0.6)\n",
        "    plt.legend(fontsize=12)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ofcztwylFDwK"
      },
      "outputs": [],
      "source": [
        "figure_2chart(\"net34\", l34,a34,lp34,ap34)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZxzAJp1Ht9P2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imU18BpokSTf",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "class_names = labels_list\n",
        "display_predictions(trainloader_2, resnet34, class_names, device, n_images=9)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c4NeaXZiIjRv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nTiwTYZdFDwQ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}