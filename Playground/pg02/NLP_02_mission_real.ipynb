{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c8c4ac4-c84a-4aa2-84ec-9f06363d5a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.9.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.12/site-packages (from nltk) (8.2.1)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.12/site-packages (from nltk) (1.5.1)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Downloading regex-2026.1.15-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.12/site-packages (from nltk) (4.67.1)\n",
      "Downloading nltk-3.9.2-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2026.1.15-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (803 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.6/803.6 kB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: regex, nltk\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [nltk][32m1/2\u001b[0m [nltk]\n",
      "\u001b[1A\u001b[2KSuccessfully installed nltk-3.9.2 regex-2026.1.15\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14de2b90-4221-4d6b-8011-a00b7361575b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"averaged_perceptron_tagger\")\n",
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2356189f-d786-44de-b916-14a544e216a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text\n",
      "0                        The Tesseract has awakened.\n",
      "1           It is on a neutral world, a human world.\n",
      "2                              They wield its power,\n",
      "3  but our ally knows it's working, so that they ...\n",
      "4  He's ready to lead, and our force, our Chitaur...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1545 entries, 0 to 1544\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    1545 non-null   object\n",
      "dtypes: object(1)\n",
      "memory usage: 12.2+ KB\n",
      "None\n",
      "The Tesseract has awakened.\n",
      "It is on a neutral world, a human world.\n",
      "They wield its power,\n",
      "but our ally knows it's working, so that they never will learn.\n",
      "He's ready to lead, and our force, our Chitauri will follow.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. CSV 파일 읽기 (인코딩 주의: utf-8, cp949, utf-8-sig 등)\n",
    "# df = pd.read_csv('test.csv', encoding='utf-8')\n",
    "# df = pd.read_csv('test.csv')\n",
    "\n",
    "# 2. 데이터 구조 확인 (텍스트가 포함된 컬럼 찾기)\n",
    "\n",
    "# 3. 필요한 텍스트 컬럼만 추출\n",
    "# texts = df['text_column'].astype(str) # 텍스트 데이터가 있는 컬럼명 입력\n",
    "column_names = ['text'] # Since you expect only one column\n",
    "df = pd.read_csv('test.csv', names=column_names, header=None, sep='₩',engine='python')\n",
    "\n",
    "\n",
    "\n",
    "print(df.head())\n",
    "print(df.info())\n",
    "for i in range(5):\n",
    "    text_content = df.iloc[i,0]\n",
    "    print(text_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedc0d24-daca-4c20-a5aa-91658d3b1b42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92495249-9efe-4382-991e-f3a5860465b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "49a31b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367\n"
     ]
    }
   ],
   "source": [
    "from nltk import tokenize\n",
    "from nltk import tag\n",
    "import re\n",
    "\n",
    "text = \"Hello, World! 123 @# 한글_테스트.\"\n",
    "\n",
    "# 영문, 숫자, 한글, 공백을 제외한 나머지 특수문자 제거\n",
    "cleaned_text = re.sub(r'[^a-zA-Z0-9가-힣 ]', '', text)\n",
    "dic_voca = {}\n",
    "for row in df['text']:\n",
    "    # print(index,row)\n",
    "    text = re.sub(r'[^a-zA-Z0-9 ]', '', row.lower())\n",
    "    # print(text)\n",
    "    word_tokens = tokenize.word_tokenize(text)\n",
    "    sent_tokens = tokenize.sent_tokenize(text)\n",
    "    pos = tag.pos_tag(word_tokens)\n",
    "\n",
    "    for token in word_tokens:\n",
    "        if token in dic_voca:\n",
    "            # 이미 있는 단어면 카운트 증가\n",
    "            dic_voca[token] += 1 \n",
    "        else:\n",
    "            # 처음 보는 단어면 1로 초기화\n",
    "            dic_voca[token] = 1\n",
    "            \n",
    "print(dic_voca[\"you\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "21f7cd70-a991-4d29-816b-bdadae126606",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "af8eaa08-9978-465c-90dd-52489fe6966b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      rank  num         text\n",
      "0        1  367          you\n",
      "1        2  365          the\n",
      "2        3  249            i\n",
      "3        4  224            a\n",
      "4        5  224           to\n",
      "...    ...  ...          ...\n",
      "1925  1926    1         10cb\n",
      "1926  1927    1      bshield\n",
      "1927  1928    1  accelerator\n",
      "1928  1929    1     factoryb\n",
      "1929  1930    1        argue\n",
      "\n",
      "[1930 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 2. 정렬 (빈도수 내림차순)\n",
    "# 결과: [('you', 367), ('the', 365), ...]\n",
    "sorted_list = sorted(dic_voca.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "df_result = pd.DataFrame(sorted_list, columns=['text', 'num'])\n",
    "df_result['rank'] = df_result.index + 1\n",
    "vocab = df_result[['rank', 'num', 'text']]\n",
    "\n",
    "df_result['level'] = df_result['num'].apply(lambda x: 'High' if x >= 200 else 'Low')\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063acfe4-d8d6-4205-ac10-a390d17a8d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def integer input(text):\n",
    "    cleaned_text = re.sub(r'[^a-zA-Z0-9가-힣 ]', '', text)\n",
    "\n",
    "\n",
    "    if token in vocab[\"text\"]:\n",
    "        # 이미 있는 단어면 카운트 증가\n",
    "        vocab[\"rank\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
